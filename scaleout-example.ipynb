{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScaleOut Exercise\n",
    "\n",
    "**NOTE: If you got an error saying `hats-sci-pi` doesn't exist, close and halt this notebook and run the 1-pyroot-setup notebook, then come back and change the kernel of this notebook back to `hats-sci-pi`**\n",
    "\n",
    "One important component of scaling out computation is decomposing it into smaller independent chunks, which can then be executed on multiple resources simultaneously. Let's do this on a simplified example to see what this looks like and what can go wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT as r\n",
    "r.gDebug = 0\n",
    "import json\n",
    "import pprint\n",
    "import random\n",
    "from ConfigParser import RawConfigParser\n",
    "config = RawConfigParser()   \n",
    "config.optionxform = str       # Last two lines are done because ConfigParser will not preserve case\n",
    "config.read(\"hatsConfig.ini\")\n",
    "fullCrossSections = dict([sample, float(xsec)] for sample, xsec in config.items('hatsXsects'))\n",
    "nProcessed    = dict([sample, int(nPro)] for sample, nPro in config.items('hatsNprocessed'))\n",
    "varNames=['dijetEtBalance', 'dijetMass']\n",
    "fileList = json.loads(open(\"filelist.json\").read())\n",
    "fullHatsChains = {}\n",
    "shortHatsChains = {}\n",
    "for sample in fileList.keys():\n",
    "    chain = r.TChain('hatsDijets')\n",
    "    shortChain = r.TChain('hatsDijets')\n",
    "    random.shuffle(fileList[sample])\n",
    "    sampleList = fileList[sample]\n",
    "    shortChain.Add(\"/mnt/hdfs/\" + sampleList[0])\n",
    "    for hatsFile in sampleList:\n",
    "        chain.Add(\"/mnt/hdfs/\" + hatsFile)\n",
    "    fullHatsChains[sample] = chain\n",
    "    shortHatsChains[sample] = shortChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change this to either run the full or short data\n",
    "As you're debugging, it can help to run on a shortened dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hatsChains = fullHatsChains ; crossSections = fullCrossSections\n",
    "hatsChains = fullHatsChains ; crossSections = dict(fullCrossSections.items()[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An \"Analysis\"\n",
    "To give us something to work with, consider the analysis below. This code will plot several kinematics from multiple samples, then store the histograms in a variable named \"hist\".\n",
    "\n",
    "This is obviously trivial (and incredibly slow), but the \"meat\" of the analysis isn't what's important, it's the decomposition we care about. Looking at this code, what can be pulled apart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hists = {}\n",
    "import time\n",
    "tic = time.time()\n",
    "for sample in crossSections.keys():\n",
    "    for varName in varNames:\n",
    "        hatsChains[sample].SetBranchStatus('*', 0)\n",
    "        hatsChains[sample].SetBranchStatus(varName, 1)\n",
    "        histLabel = \"%s_%s\" % (varName, sample)\n",
    "        hists[histLabel]=r.TH1F(histLabel, histLabel, 100, 0, 0)\n",
    "        hatsChains[sample].Draw(\"%s>>%s\" % (varName, histLabel))\n",
    "toc = time.time()\n",
    "print(\"Time elapsed: %0.2fsecs\" % (toc - tic))\n",
    "pprint.pprint(hists)\n",
    "canvas = r.TCanvas()\n",
    "hists['dijetEtBalance_QCD_HT500to700'].Draw()\n",
    "canvas.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## The technique\n",
    "One method of decomposition is to separate a loop from its body, so the body can be explicitly run elsewhere and still produce the same results.\n",
    "\n",
    "It's important that the decomposed body doesn't change or access any global state (think about why that's necessary to scale out on multiple CPUs or machines). What in the body of this loop should be changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = {}\n",
    "tic = time.time()\n",
    "for x in range(8):\n",
    "    time.sleep(1)\n",
    "    vals[x] = x ** 2\n",
    "toc = time.time()\n",
    "print(\"Time elapsed: %0.2fsecs\" % (toc - tic))\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizing\n",
    "With some thought, we can decompose the body of our loop into a new function `sleep_some`.\n",
    "\n",
    "Note that there was two changes made:\n",
    "1. The loop variable `x`, which is normally implicitly passed from the loop into the body is turned into an explicit argument of our new function.\n",
    "2. Instead of modifying `vals` to return data from the body of the loop, we pass it back to the caller as a return value.\n",
    "\n",
    "Once we have our new function, we can then use `concurrent.futures`'s `ThreadPoolExecutor` to execute all 8 of our loop bodies in separate threads at the same time, which should mean it runs 8 times as fast as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our \"important\" code into a separate function\n",
    "def sleep_some(x):\n",
    "    time.sleep(1)\n",
    "    return (x, x ** 2)\n",
    "\n",
    "# Make a thread pool to execute it\n",
    "import concurrent.futures\n",
    "tic = time.time()   \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=8) as p:\n",
    "    # Run one copy of every function on a separate thread simultaneously\n",
    "    ret = p.map(sleep_some, range(8))\n",
    "# Convert our return value into a dict to match the output from the previous cell\n",
    "vals = dict(ret)\n",
    "toc = time.time()\n",
    "print(\"Time elapsed: %0.2fsecs\" % (toc - tic))\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn\n",
    "\n",
    "Following the pattern above, decompose our \"analysis\" to use multiple threads. Once you have it debugged, run both the original and modified versions with the full dataset and compare the runtimes. Make sure the outputs are the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE HERE\n",
    "#\n",
    "\n",
    "print(\"Time elapsed: %0.2fsecs\" % (toc - tic))\n",
    "pprint.pprint(hists)\n",
    "canvas = r.TCanvas()\n",
    "hists['dijetEtBalance_QCD_HT500to700'].Draw()\n",
    "canvas.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our \"important\" code into a separate function\n",
    "def sleep_some(x):\n",
    "    time.sleep(1)\n",
    "    return (x, x ** 2)\n",
    "\n",
    "\n",
    "# Make a thread pool\n",
    "import concurrent.futures    \n",
    "tic = time.time()   \n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=8) as p:\n",
    "    # Run one copy of every function on a separate thread simultaneously\n",
    "    ret = p.map(sleep_some, range(8))\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Time elapsed: %0.2fsecs\" % (toc - tic))\n",
    "print(dict(ret))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hats-sci-py",
   "language": "python",
   "name": "hats-sci-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
